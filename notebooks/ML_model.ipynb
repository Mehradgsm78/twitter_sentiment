{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62910997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e737b9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"/Users/mehradghassemi/twitter_sentiment/data/interim/train_data.npy\", allow_pickle=True)\n",
    "dev_data = np.load(\"/Users/mehradghassemi/twitter_sentiment/data/interim/dev_data.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5230f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentiment(category):\n",
    "    if category == \"positive\":\n",
    "        return 2\n",
    "    elif category ==\"neutral\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c8e651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.concatenate([train_data, dev_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cd83c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[569731104070115329 'positive' 1.0 ... '2015-02-22 21:30:54 -0800'\n",
      "  'Washington D.C. ' 'Eastern Time (US & Canada)']\n",
      " [569263373092823040 'negative' 1.0 ... '2015-02-21 14:32:19 -0800' nan\n",
      "  nan]\n",
      " [568818669024907264 'negative' 1.0 ... '2015-02-20 09:05:13 -0800'\n",
      "  'Arlington, VA' 'Atlantic Time (Canada)']\n",
      " ...\n",
      " [569964335038124033 'negative' 1.0 ... '2015-02-23 12:57:41 -0800' nan\n",
      "  nan]\n",
      " [569208236487745536 'negative' 0.6765 ... '2015-02-21 10:53:13 -0800'\n",
      "  nan 'Central Time (US & Canada)']\n",
      " [569489032100614144 'neutral' 0.6416 ... '2015-02-22 05:29:00 -0800'\n",
      "  'Virginia, USA' nan]]\n"
     ]
    }
   ],
   "source": [
    "print(all_data)   ##1 index is category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18ba597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = [convert_sentiment(x) for x in all_data[:,1]]\n",
    "all_text = all_data[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00ff0475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing random search...\n",
      "pipeline: ['tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__max_depth': (None, 5, 10, 15),\n",
      " 'clf__min_samples_split': (2, 4, 6),\n",
      " 'clf__n_estimators': (100, 1000, 5000),\n",
      " 'tfidf__max_df': (0.9, 0.95, 1.0),\n",
      " 'tfidf__max_features': (None, 5000, 10000, 50000),\n",
      " 'tfidf__min_df': (0.1, 0.05, 0.0),\n",
      " 'tfidf__ngram_range': ((1, 1), (1, 2), (2, 2)),\n",
      " 'tfidf__norm': ('l1', 'l2'),\n",
      " 'tfidf__stop_words': ('english', None)}\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehradghassemi/twitter_sentiment/env/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/mehradghassemi/twitter_sentiment/env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "80 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mehradghassemi/twitter_sentiment/env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/mehradghassemi/twitter_sentiment/env/lib/python3.9/site-packages/sklearn/pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/mehradghassemi/twitter_sentiment/env/lib/python3.9/site-packages/sklearn/pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/mehradghassemi/twitter_sentiment/env/lib/python3.9/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/mehradghassemi/twitter_sentiment/env/lib/python3.9/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/mehradghassemi/twitter_sentiment/env/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\", line 2133, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "  File \"/Users/mehradghassemi/twitter_sentiment/env/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\", line 1401, in fit_transform\n",
      "    X, self.stop_words_ = self._limit_features(\n",
      "  File \"/Users/mehradghassemi/twitter_sentiment/env/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\", line 1253, in _limit_features\n",
      "    raise ValueError(\n",
      "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/mehradghassemi/twitter_sentiment/env/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.48407332 0.62521177 0.48407332 0.48495261 0.51676528 0.58602809\n",
      " 0.58686367        nan 0.51766645 0.61754081 0.48574727 0.48407332\n",
      " 0.48407332 0.53114185        nan 0.53114185 0.53114185 0.48845167\n",
      " 0.7408383  0.66906678 0.49732815 0.6430345  0.52000198 0.53114185\n",
      " 0.57093274        nan 0.57395513 0.61844882 0.56665715 0.61167855\n",
      " 0.51119594 0.48407332 0.59512776        nan 0.48407332        nan\n",
      " 0.49779956 0.57649032 0.74051487        nan 0.53114185 0.48498943\n",
      "        nan 0.49703014 0.62755177 0.66817271 0.57478939 0.72260741\n",
      " 0.48407332 0.61094451        nan 0.59085549 0.58605509 0.73318617\n",
      " 0.48407332 0.58590935 0.49915025 0.48438449 0.50238339 0.49326666\n",
      " 0.57494762        nan 0.57522355 0.48407332        nan        nan\n",
      " 0.48387143 0.48407332        nan 0.53114185 0.62109977 0.5141923\n",
      " 0.57712183 0.51651976        nan        nan 0.67017171 0.49769934\n",
      " 0.58589478 0.49213711        nan 0.51682114 0.61201448 0.56442162\n",
      " 0.49477425 0.67056279 0.66824271 0.48407332 0.57641081 0.50063648\n",
      " 0.72423802 0.49776891        nan 0.48454227 0.64442754 0.48407332\n",
      " 0.53114185 0.67009203 0.57489059 0.53114185]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2558.738s\n",
      "\n",
      "Best score: 0.741\n",
      "Best parameters set:\n",
      "\tclf__max_depth: None\n",
      "\tclf__min_samples_split: 4\n",
      "\tclf__n_estimators: 100\n",
      "\ttfidf__max_df: 1.0\n",
      "\ttfidf__max_features: 10000\n",
      "\ttfidf__min_df: 0.0\n",
      "\ttfidf__ngram_range: (1, 2)\n",
      "\ttfidf__norm: 'l1'\n",
      "\ttfidf__stop_words: None\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "# Define the hyperparameters you want to tune\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.9, 0.95, 1.0),\n",
    "    'tfidf__min_df': (0.1, 0.05, 0.0),\n",
    "    'tfidf__stop_words': ('english', None),\n",
    "    'tfidf__max_features': (None, 5000, 10000, 50000),\n",
    "    'tfidf__ngram_range': ((1, 1), (1, 2), (2, 2)),  # unigrams or bigrams or trigrams\n",
    "    'tfidf__norm': ('l1', 'l2'), \n",
    "    'clf__n_estimators': (100, 1000, 5000),\n",
    "    'clf__max_depth': (None, 5, 10, 15), \n",
    "    'clf__min_samples_split': (2, 4, 6)\n",
    "}\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(pipeline, parameters, n_iter=100, n_jobs=-1, verbose=1, cv=5, \n",
    "                                   scoring='f1_weighted', random_state=42)\n",
    "\n",
    "\n",
    "print(\"Performing random search...\")\n",
    "print (\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print (\"parameters:\")\n",
    "pprint (parameters)\n",
    "t0 = time()\n",
    "random_search.fit(all_text, all_labels) \n",
    "print(\"done in %0.3fs\" % (time() - t0)) \n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % random_search.best_score_)\n",
    "print (\"Best parameters set:\")\n",
    "best_parameters = random_search.best_estimator_.get_params()\n",
    "for param_name in sorted (parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbe98906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/sklearn_model.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(random_search.best_estimator_, '../models/sklearn_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5dcfb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter_sentiment",
   "language": "python",
   "name": "twitter_sentiment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
